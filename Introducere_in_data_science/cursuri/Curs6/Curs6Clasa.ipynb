{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curs 6: Optimizarea modelelor, preprocesare, pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizarea modelelor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cursul anterior s-a aratat cum se poate folosi k-fold cross validation pentru estimarea performantei unui model. Totodata, s-a aratat o maniera simpla de cautare a valorilor celor mai potrivite pentru hiperparametri - in cazul respectiv. valoarea adecvata a numarului de vecini. \n",
    "\n",
    "Vom continua aceasta idee pentru mai multi hiperparametri, apoi folosim facilitatile bibliotecii `sklearn` pentru automatizarea procesului."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold cross validation ( asigura ca fiecare din cele k partitii ale setului de date initial este pe rand folosit ca subset de testare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: prettytable in c:\\anaconda3\\envs\\data-science\\lib\\site-packages\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "!pip install prettytable --upgrade\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------------------------------------------------------+---------------------------------+\n",
      "| Iter | Train                                                         | Test                            |\n",
      "+------+---------------------------------------------------------------+---------------------------------+\n",
      "| 1    | [10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29] | [0 1 2 3 4 5 6 7 8 9]           |\n",
      "| 2    | [ 0  1  2  3  4  5  6  7  8  9 20 21 22 23 24 25 26 27 28 29] | [10 11 12 13 14 15 16 17 18 19] |\n",
      "| 3    | [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] | [20 21 22 23 24 25 26 27 28 29] |\n",
      "+------+---------------------------------------------------------------+---------------------------------+\n"
     ]
    }
   ],
   "source": [
    "kf = ...\n",
    "splits = ...\n",
    "t = PrettyTable(['Iter', 'Train', 'Test'])\n",
    "t.align = 'l'\n",
    "for i, data in enumerate(splits):\n",
    "    t.add_row([i+1, data[0], data[1]])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru calculul performantei prin k-fold CV se asigura ca esantionarea se face in mod stratificat: fiecare fold are aceeasi proportie a claselor ca si in setul originar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folosim k-fold cross validation pentru a face evaluarea de modele pentru diferite valori ale hiperparametrilor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy:  1.14.2\n",
      "pandas:  0.22.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "print ('numpy: ', np.__version__)\n",
    "print ('pandas: ', pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ...\n",
    "from sklearn.neighbors import ...\n",
    "from sklearn.metrics import ...\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = ...\n",
    "X = ...\n",
    "y = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru k-nearest neighbors vom cauta valorile optime pentru:\n",
    "* numarul de vecini, $k \\in \\{1, \\dots, 31\\}$\n",
    "* putere corespunzatoare metricii Minkowski:\n",
    "$$\n",
    "d(\\mathbf{x}, \\mathbf{y}) = \\left( \\sum\\limits_{i=1}^n \\left|x_i-y_i\\right|^p \\right)^{1/p}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9800000000000001\n",
      "Best params: {'n_neighbors': 20, 'p': 2}\n",
      "Accuracy on whole set: 0.98\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "for k in range(1, 31):\n",
    "    for p in [1, 2, 3, 4.7]:\n",
    "        ...\n",
    "print('Best score:', best_score)\n",
    "print('Best params:', best_params)   \n",
    "model = ...\n",
    "model.fit(X, y)\n",
    "y_predicted = model.predict(X)\n",
    "print('Accuracy on whole set:', accuracy_score(y, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru procesul de mai sus urmatoarele comentarii sunt necesare:\n",
    "1. strategia implementata se numeste grid search: se cauta peste toate combinatiile de 30\\*4 variante si sa retine cea mai buna; este consumatoare de resurse, dar o prima varianta de lucru acceptabila\n",
    "1. am dori sa avem o modalitate automatizata de considerare a tuturor combinatiilor de parametri din multimea de valori candidat. Codul devine greu de scris cand sunt 4 hiperparametri, fiecare cu multimea proprie de valori candidat\n",
    "1. estimarea efectuata in final este de cele mai multe ori optimista: optimizarea parametrilor s-a facut peste niste date, care date in final sunt cele folosite pentru evaluarea finala; am ajuns practic sa facem evaluare pe setul de antrenare, ceea ce e o idee proasta. Estimarea finala a performantelor modelului trebuie facuta peste un set de date aparte, care nu a fost folosit nici pentru antrenare, nici pentru validarea modelelor candidat. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru ultimul punct se recomanda ca setul sa fie impartit ca mai jos:\n",
    "![train_validation_test](./images/train_validation_test.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ca atare, va trebui sa rescriem codul astfel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9825757575757577\n",
      "Best params: {'n_neighbors': 15, 'p': 3}\n",
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=1/5)\n",
    "...\n",
    "print('Best score:', best_score)\n",
    "print('Best params:', best_params)   \n",
    "\n",
    "model = ...\n",
    "model.fit...\n",
    "y_predicted = model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desigur, si implementarea de mai sus e criticabila: s-a facut evaluare pe un singur set de testare, anume cel rezultat dupa impartirea initiala in partitiile \\*\\_trainvalid si \\*\\_test. Este totusi o estimare mai corect facuta decat cea precedenta.  In realitate, acest stil de lucru este frecvent intalnit: exista un set de testare unic, dar necunoscut la inceput. Singurele date disponibile sunt impartite in *training set* si *validation set* (eventual mai multe) pentru a obtine un model care se spera ca generalizeaza bine = se comporta bine pe setul de testare. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Varianta anterioara se numeste **grid search with cross validation**. Exista clasa `sklearn.model_selection.GridSearchCV` care automatizeaza procesul:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/5)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "y_estimated = grid_search.predict(X_test)\n",
    "print(accuracy_score(y_test, y_estimated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In codul anterior denumirile cheilor din dictionarul `parameter_grid` nu sunt intamplatoare: ele coincid cu numele parametrilor modelului vizat. Instantierea `estimator = KNeighborsClassifier()` se face cu valorile implicite ale parametrilor, apoi insa se ruleaza metode de tip `set_` care seteaza parametrii dati in dictionarul `parameter_grid`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru cei interesati, valorile de performanta pentru fiecare fold se pot inspecta in campul `cv_results_`. Pentru ca acestea sa fie disponibile, este obligatorie setarea parametrului `return_train_score=True` din clasa `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36 entries, 0 to 35\n",
      "Data columns (total 22 columns):\n",
      "mean_fit_time         36 non-null float64\n",
      "mean_score_time       36 non-null float64\n",
      "mean_test_score       36 non-null float64\n",
      "mean_train_score      36 non-null float64\n",
      "param_n_neighbors     36 non-null object\n",
      "param_p               36 non-null object\n",
      "params                36 non-null object\n",
      "rank_test_score       36 non-null int32\n",
      "split0_test_score     36 non-null float64\n",
      "split0_train_score    36 non-null float64\n",
      "split1_test_score     36 non-null float64\n",
      "split1_train_score    36 non-null float64\n",
      "split2_test_score     36 non-null float64\n",
      "split2_train_score    36 non-null float64\n",
      "split3_test_score     36 non-null float64\n",
      "split3_train_score    36 non-null float64\n",
      "split4_test_score     36 non-null float64\n",
      "split4_train_score    36 non-null float64\n",
      "std_fit_time          36 non-null float64\n",
      "std_score_time        36 non-null float64\n",
      "std_test_score        36 non-null float64\n",
      "std_train_score       36 non-null float64\n",
      "dtypes: float64(18), int32(1), object(3)\n",
      "memory usage: 6.1+ KB\n"
     ]
    }
   ],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_p</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002407</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 1, 'p': 1}</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001021</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.027496</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003611</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 1, 'p': 2}</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.027496</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002605</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_neighbors': 1, 'p': 3}</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>0.027496</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.004811</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>{'n_neighbors': 1, 'p': 4.7}</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>0.027496</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.002207</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.974954</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 2, 'p': 1}</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.957895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.034298</td>\n",
       "      <td>0.008531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.002407         0.003008         0.958333          1.000000   \n",
       "1       0.003611         0.005013         0.958333          1.000000   \n",
       "2       0.002605         0.003811         0.958333          1.000000   \n",
       "3       0.001606         0.004811         0.958333          1.000000   \n",
       "4       0.001202         0.002207         0.941667          0.974954   \n",
       "\n",
       "  param_n_neighbors param_p                        params  rank_test_score  \\\n",
       "0                 1       1    {'n_neighbors': 1, 'p': 1}               29   \n",
       "1                 1       2    {'n_neighbors': 1, 'p': 2}               29   \n",
       "2                 1       3    {'n_neighbors': 1, 'p': 3}               29   \n",
       "3                 1     4.7  {'n_neighbors': 1, 'p': 4.7}               29   \n",
       "4                 2       1    {'n_neighbors': 2, 'p': 1}               36   \n",
       "\n",
       "   split0_test_score  split0_train_score       ...         split2_test_score  \\\n",
       "0                1.0            1.000000       ...                  0.958333   \n",
       "1                1.0            1.000000       ...                  0.958333   \n",
       "2                1.0            1.000000       ...                  0.958333   \n",
       "3                1.0            1.000000       ...                  0.958333   \n",
       "4                1.0            0.957895       ...                  0.958333   \n",
       "\n",
       "   split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0            1.000000           0.956522            1.000000   \n",
       "1            1.000000           0.956522            1.000000   \n",
       "2            1.000000           0.956522            1.000000   \n",
       "3            1.000000           0.956522            1.000000   \n",
       "4            0.979167           0.913043            0.979381   \n",
       "\n",
       "   split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.913043            1.000000      0.001021        0.000634   \n",
       "1           0.913043            1.000000      0.001966        0.001678   \n",
       "2           0.913043            1.000000      0.001360        0.000982   \n",
       "3           0.913043            1.000000      0.000492        0.001944   \n",
       "4           0.913043            0.979381      0.000399        0.000401   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.027496         0.000000  \n",
       "1        0.027496         0.000000  \n",
       "2        0.027496         0.000000  \n",
       "3        0.027496         0.000000  \n",
       "4        0.034298         0.008531  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grid_search.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru situatia in care se doreste evaluarea nu doar pe un singur set de testare, ci in stil cross-validation, se poate face un *nested cross-validation*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metode de preprocesare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uneori, inainte de aplicarea vreunui model, este nevoie ca datele de intrare sa fie supuse unor transformari. De exemplu, daca pentru algoritmul k-NN vreuna din trasaturi (fie ea *F*) are valori de ordinul sutelor si celelalte de ordinul unitatilor, atunci distanta dintre doi vectori ar fi dominata de diferenta pe dimensiunea *F*; celelalte dimensiuni nu ar conta prea mult.\n",
    "\n",
    "Intr-o astfel de situatie se recomanda sa se faca o scalare in prealabil a datelor la intervale comparbile, de ex [0, 1]. \n",
    "\n",
    "In modulul `sklearn.preprocessing` se afla clasa `MinMaxScaler` care permite scalarea independenta a trasaturilor. Il vom demonstra pe un set de date care are trasaturi cu marimi disproportionate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ranges(X):\n",
    "    ...\n",
    "        \n",
    "print_ranges(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 0.9999999999999999\n",
      "0.0 1.0\n",
      "0.0 0.9999999999999999\n",
      "0.0 0.9999999999999999\n",
      "0.0 0.9999999999999999\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 0.9999999999999999\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0000000000000002\n",
      "0.0 1.0\n",
      "0.0 0.9999999999999999\n",
      "0.0 1.0\n",
      "0.0 0.9999999999999999\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 0.9999999999999999\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 0.9999999999999998\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 0.9999999999999999\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "...\n",
    "print_ranges(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De mentionat ca secventa `fit` si `transform` se poate apela intr-un singur pas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 0.9999999999999999\n",
      "0.0 1.0\n",
      "0.0 0.9999999999999999\n",
      "0.0 0.9999999999999999\n",
      "0.0 0.9999999999999999\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 0.9999999999999999\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0000000000000002\n",
      "0.0 1.0\n",
      "0.0 0.9999999999999999\n",
      "0.0 1.0\n",
      "0.0 0.9999999999999999\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 0.9999999999999999\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 0.9999999999999998\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 0.9999999999999999\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "X, y = medical.data, medical.target\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De regula, setul de date se imparte in doua (in modul naiv): set de antrenare si set de testare. Se presupune ca setul de testare este cunoscut mult mai tarziu decat cel de antrenare. Ca atare, doar cel de antrenare se trece prin preprocesor, iar  valorile 'invatate' via `fit ` se pastreaza (obiectul de tip `MinMaxScaler` are stare). ele vor fi folosite pentru scalarea setului de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03659670238269972 1.033758990165859\n",
      "0.07372336827866077 0.8150152181264796\n",
      "0.02885891971210963 1.011180211026483\n",
      "0.014973488865323448 0.9991516436903501\n",
      "-0.09792843691148768 0.6917434830012885\n",
      "0.02183915097233299 0.8957119195141405\n",
      "0.0 0.7823336457357076\n",
      "0.0 0.9169980119284297\n",
      "0.0722222222222223 0.7621212121212122\n",
      "0.00610783487784361 0.9644060657118789\n",
      "-0.0011921400970155386 1.1340129902162293\n",
      "0.0005746110325318271 0.7263967468175389\n",
      "0.005108142849158894 1.1861062985525066\n",
      "-0.0009796699783500406 0.9689646533576132\n",
      "0.03824319271169731 0.6818166366386782\n",
      "0.01122059662931475 0.6866644636044102\n",
      "0.0 0.7671717171717172\n",
      "0.0 0.6518279977268423\n",
      "0.02331569764169529 0.5946136095007598\n",
      "-0.002545745487796006 0.7260292951229059\n",
      "0.03678406261117046 0.8210601209533975\n",
      "0.07462686567164184 0.8899253731343283\n",
      "0.033667015289606084 0.8032770556302604\n",
      "0.014009044435705859 0.7269465198584348\n",
      "0.11952679795138145 1.0923321070475367\n",
      "0.015503875968992255 0.8834783789814787\n",
      "0.0 1.07008547008547\n",
      "0.0 0.9852233676975946\n",
      "0.016361127537946 0.7871082199881728\n",
      "0.0011150465695920486 0.6136691591237047\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3)\n",
    "scaler = MinMaxScaler()\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se remarca faptul ca, folosindu-se parametrii de scalare din setul de antrenare, nu se poate garanta ca setul de testare este cuprins de asemenea in hipercubul unitate $[0, 1]^{X.shape[1]}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exista si alte metode de preprocesare in modulul [`sklearn.preprocessing`](http://scikit-learn.org/stable/modules/preprocessing.html). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se prefera inlantuirea intr-un proces a pasilor: preprocesare si aplicare de model. Exemplificam pentru cazul simplu in care exista un set de antrenare si unul de testare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = medical.data, medical.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9842105263157894\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru cazul in care se vrea k-fold cross validation pentru determinarea valorilor optime pentru hiperparametri, urmata de testare pe un set de testare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'knn__n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'knn__p': [1, 2, 3, 4.7]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=1/3)\n",
    "parameter_grid = {'knn__n_neighbors': list(range(1, 10)), 'knn__p': [1, 2, 3, 4.7]}\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9631578947368421\n"
     ]
    }
   ],
   "source": [
    "y_predicted = ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
