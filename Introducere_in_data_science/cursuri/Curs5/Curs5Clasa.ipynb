{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curs 5: Regresia liniara, evaluarea si selectarea naiva a modelelor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prin regresie se doreste estimarea unei valori continue: temperatura sau presiunea dintr-un proces fizic, valoarea estimata pentru un serviciu/bun cumparat etc. Prin comparatie, clasificarea dorea estimarea unei valori de iesire dintr-o multime finita de posibilitati (clase)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Regresia liniara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplu de problema\n",
    "\n",
    "Sa presupunem ca dorim sa modelam pretul de vanzare al unei proprietati imobiliare, *e.g.* o casÄƒ. Se cunosc $p$ cazuri de vanazare-cumparare de case. Fiecare casa vanduta este descrisa printr-un set de trasaturi (eng: features) cum ar fi: suprafata (sau numarul de camere), distanta de la ea pana la centrul orasului, gradul de poluare a zonei etc. - toate valori numerice. De asemenea, pentru fiecare casa se cunoaste care a fost pretul de vanzare-cumparare. Un astfel de set de date este [Boston housing](https://archive.ics.uci.edu/ml/machine-learning-databases/housing/). \n",
    "\n",
    "Se doreste a se construi un model care, plecand de la datele furnizate, sa fie capabil sa \"invete\" sa aproximeze valoarea unei noi proprietati pentru care valorile de intrare (trasaturile) se cunosc.\n",
    "\n",
    "Avem de-a face cu:\n",
    "* problema de instruire supervizata (se cunosc asocieri intre trasaturi de intrare - valoare de iesire);\n",
    "* problema de regresie - valoarea estimata este una continua, nu dintr-o multime predefinita de clase. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresia liniara\n",
    "\n",
    "Se poate consulta Cursul 2 din [Sisteme computationale inteligente, note de curs](https://github.com/lmsasu/cursuri/blob/master/SistemeComputationaleInteligente/SistemeComputationaleInteligente.pdf), pentru expunere mai ampla, algoritm de instruire bazat pe stochastic gradient descent si metoda ecuatiilro normale. O scurta descriere este data mai jos. \n",
    "\n",
    "Notatii:\n",
    "* $x_1, x_2, \\dots, x_n$: valorile numerice aferente unei case: suprafata, distanta pana la centrul orasului etc. \n",
    "* $\\theta_0, \\theta_1, \\dots, \\theta_n$ sunt coeficienti care trebuie determinati. Se observa ca avem cu un coeficient mai mult decat valori de trasaturi. \n",
    "\n",
    "In regresia liniara se presupune ca valoarea de iesire (pretul) variaza liniar cu valorile trasaturilor de intrare. Se noteaza un astfel de model cu $h$; dependenta lui de un vector de coeficienti - numit si vectori de ponderi (eng: weights) - se marcheaza explicit prin notatia $h_\\theta$. Forma modelului este:\n",
    "$$\n",
    "h_{\\theta}(\\mathbf{x}) = \\theta_0 + \\theta_1 \\cdot x_1 + \\theta_2 \\cdot x_2 + \\dots +\\theta_n \\cdot x_n\n",
    "$$\n",
    "Primul termen al expresiei de dupa egal se poate scrie sub forma: $\\theta_0 \\cdot 1$. Daca notam cu $x_0$ valoarea constanta 1, asta ne permite sa consideram doi vectori cu $n+1$ componente:\n",
    "* $\\mathbf{x} = \\begin{pmatrix}\n",
    "x_0 \\\\\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "\\vdots \\\\\n",
    "x_n\n",
    "\\end{pmatrix}\n",
    "$ este vectorul de intrare continand caracteristicile numerice ale unei case oarecare;\n",
    "* $\\boldsymbol{\\theta} = \\begin{pmatrix}\n",
    "\\theta_0 \\\\\n",
    "\\theta_1 \\\\\n",
    "\\vdots \\\\\n",
    "\\theta_n\n",
    "\\end{pmatrix}\n",
    "$ este vectorul de coeficienti.\n",
    "\n",
    "Relatia de mai sus pentru $h_{\\theta}$ se scrie mai concis astfel:\n",
    "$$\n",
    "    h_\\theta(\\mathbf{x}) =  \\boldsymbol{\\theta}^t \\cdot \\mathbf{x} \n",
    "$$\n",
    "care, desigur, in NumPy se scrie cu \n",
    "```python\n",
    "np.dot(theta, x)\n",
    "```\n",
    "\n",
    "Ceea ce trebuie facut este determinarea coeficientilor din vectorul $\\boldsymbol{\\theta}$ pentru care valoarea medie a patratelor diferentelor dintre estimarea facuta de model pentru valoarea de vanzare a unei case si valoarea ei cunoscuta sa fie cat mai mica:\n",
    "$$\n",
    "J(\\boldsymbol{\\theta}) = \\frac{1}{2p} \\sum\\limits_{i=1}^p \\left( h_{\\theta}(\\mathbf{x}_i) - y_i \\right)^2\n",
    "$$\n",
    "unde: $p$ este numarul de cazuri de vanzare cunoscute, $\\mathbf{x}_i$ este vectorul de trasaturi pentru casa $i$, $y_i$ este suma cu care s-a vandut aceasta casa. \n",
    "\n",
    "Modelul rezultat este simplu, popular, interpretabil. Poate fi insa prea simplist pentru destul de multe cazuri.  \n",
    "\n",
    "Sunt doua variante de determinarea a acelui vector de coeficienti $\\boldsymbol{\\theta}$ care face ca valoarea functiei de eroare sa fie minima. Cititorul poate consulta cursul indicat la inceputul sectiunii. Noi vom folosi implementari din biblioteca scikit learn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setul de date\n",
    "\n",
    "Setul de date este [Boston housing](https://archive.ics.uci.edu/ml/machine-learning-databases/housing/): \"Concerns housing values in suburbs of Boston\", cu 506 instante (case vandute), 13 trasaturi de intrare. Toate valorile sunt precizate. Descrierea setului de date se gaseste [aici](https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.names)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citirea datelor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_housing = 'https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#citire date, delimitator regex\n",
    "data_house = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_house.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_house.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impartirea setului de date in set de antrenare si set de testare\n",
    "\n",
    "Ca si in cazul problemelor de clasificare, o parte din date vor fi folosite pentru antrenare, iar modeul rezultate va fi testat pe restul de date - setul de testare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separare X si y\n",
    "X = ...\n",
    "y = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reprezentare de valori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "#reprezentare RN versus price\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#reprezentare fiecare trasatura de intrare fata de pret\n",
    "for index, name in enumerate(names[:-1]):\n",
    "    plt.scatter(X_train[:, index], y_train)\n",
    "    plt.xlabel(name)\n",
    "    plt.ylabel('Median value of owner-occupied homes in $1000''s')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construirea modelului"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiere model LinearRegression, antrenare\n",
    "model ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tiparirea coeficientilor rezultati\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictie pe setul de test\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#afisarea primelor trei predictii\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculare metricilor de eroare\n",
    "\n",
    "Ne intereseaza cat de deparrate sunt valorile prezise de cele actuale. Aceasta se face pe baza unor metrici de eroare. Sunt mai multe metrici care se pot considera pentru o problema de regresie:\n",
    "1. Mean absolute error (MAE):\n",
    "$$\n",
    "MAE = \\frac{1}{n}\\sum\\limits_{i=1}^n \\left|y_i - \\hat{y}_i\\right|\n",
    "$$\n",
    "unde $n$ e numarul de cazuri peste care modelul a produs estimari - de exemplu, numarul de cazuri din setul de testare.\n",
    "1. Root mean squared error (RMSE):\n",
    "$$\n",
    "RMSE = \\sqrt{\\frac{1}{n} (y_i - \\hat{y}_i)^2}\n",
    "$$\n",
    "1. Intrucat functia radical este crescatoare, se prefera uneori a se renunta la radical, obtinand Mean squared error (MSE):\n",
    "$$\n",
    "MSE = \\frac{1}{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "In sklearn exista modulul `sklearn.metrics` care contine functii si clase dedicate calculului metricilor de eroare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putem incerca cu diferite subsetui de trasaturi. De exemplu, atributul CHAS este descris in documentatie ca 'Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)'. Putem incerca sa vedem cum functioneaza modelul de regresie fara el:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_woCHAS = ...\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_noCHAS = data_house_noCHAS.values[:, :-1]\n",
    "y_noCHAS = data_house_noCHAS.values[:, -1]\n",
    "\n",
    "X_train_noCHAS, X_test_noCHAS, y_train_noCHAS, y_test_noCHAS = train_test_split(X_noCHAS, y_noCHAS, test_size=0.34)\n",
    "\n",
    "#instantiere model, antrenare\n",
    "model = LinearRegression(normalize=False)\n",
    "model.fit(X_train_noCHAS, y_train_noCHAS)\n",
    "\n",
    "#predictie pe setul de test\n",
    "y_hat = model.predict(X_test_noCHAS)\n",
    "\n",
    "mae = metrics.mean_absolute_error(y_test_noCHAS, y_hat)\n",
    "mse = metrics.mean_squared_error(y_test_noCHAS, y_hat)\n",
    "rmse = np.sqrt(mse)\n",
    "print('mae={0}, mse={1}'.format(mae, mse))\n",
    "\n",
    "#se remarca o usoara imbunatatire ambelor scoruri. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model liniar cu regularizare L2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularizarea are ca scop reducerea in valoare absoluta a coeficientilor $\\theta_1, \\theta_2, \\dots, \\theta_n$ (se remarca absenta termenului liber din multimea coeficientilor regularizati). Daca coeficientii sunt mari in valoare absoluta, atunci variatii mici ale valorilor de intrare duc la variatii mari ale iesirii, ceea ce corespunde unui sistem instabil.\n",
    "\n",
    "Functia de cost se modifica astfel:\n",
    "$$\n",
    "J(\\boldsymbol{\\theta}) = \\frac{1}{2p} \\sum\\limits_{i=1}^p \\left( h_{\\theta}(\\mathbf{x}_i) - y_i \\right)^2 + \\sum\\limits_{j=1}^{n} \\theta_j^2\n",
    "$$\n",
    "\n",
    "Implementarea in `sklearn` este continuta in biblioteca `sklearn.linear_model` in clasa `Ridge`. \n",
    "\n",
    "Exista si varianta in care termenul de regularizare se bazeaza pe valorile absolute ale coeficientilor:\n",
    "$$\n",
    "J(\\boldsymbol{\\theta}) = \\frac{1}{2p} \\sum\\limits_{i=1}^p \\left( h_{\\theta}(\\mathbf{x}_i) - y_i \\right)^2 + \\sum\\limits_{j=1}^{n} \\left|\\theta_j\\right|\n",
    "$$\n",
    "Modelul corespunzator se numeste Lasso (Least Absolute Shrinkage and Selection Operator), iar implementarea se afla in clasa `Lasso` din acelasi pachet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(alpha=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)\n",
    "mae = metrics.mean_absolute_error(y_test, y_hat)\n",
    "mse = metrics.mean_squared_error(y_test, y_hat)\n",
    "\n",
    "print(\"mae={0}, mse={1}\".format(mae, mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lasso(alpha=0.001)\n",
    "model.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)\n",
    "mae = metrics.mean_absolute_error(y_test, y_hat)\n",
    "mse = metrics.mean_squared_error(y_test, y_hat)\n",
    "\n",
    "print(\"mae={0}, mse={1}\".format(mae, mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Evaluarea modelelor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluarea calitatii unui model se poate face pe:\n",
    "1. setul de antrenare - dar acest stil de lucru tinde sa favorizeze aparitia unor modele complexe, care invata bine setul de antranare, dar nu generalizeaza bine in afara lui (overfitting)\n",
    "1. un set de testare separat fata de setul de antrenare - o idee mai buna, care tinde sa incurajeze modelele care se comporta bine si pe altceva decat setul de antrnare; overfitting-ul este redus ca incidenta; totusi, exista o problema: rezultatul evaluarii deoinde de o unica masuratoare - pe unicul set de date de testare, deci poate fi prea optimista sau prea pesimista;\n",
    "1. mai multe seturi de testare; in particular, putem cere impartirea unui set de testare in $k$ subseturi de dimensiuni (cat mai) egale; pe rand, fiecare din cele $k$ seturi este folosit drept set de testare, iar celelalte $k-1$ subseturi sunt pentru antrenarea modelului La final se face media celor $k$ scoruri, determinand un scor mediu, mai apropiat de realitate. varianta descrisa se numeste k-fold cross validation si este reprezentata mai jos pentru $k=10$:\n",
    "![k fold cross validation](./images/k-fold-diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplificare: k-fold cross validation pentru un model de clasificare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vom folosi pentru exemplificare k-NN; nu exista nicio legatura intre $k$ -- numarul de vecini si $k$ - numarul de fold-uri considerat, cele doua folosind intamplator aceeasi litera pentru a denota un hiperparametru al modelului, respectiv numarul de partitii ale setului de antrenare. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In primul pas vom demonstra variabilitatea rezultatelor instruirii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterare peste 5 partitionari aleatoare\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putem face o medie a numerelor rezultate si aceasta valoare este o estimare mai realista a performantei clasificatorului. Prin k-fold cross validation, insa, se are in vedere ca fiecare inregistrare din setul initial sa fie folosit pentru testare, in mod garantat. De asemenea, fiecare inregistrare se foloseste pentru antrenare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desigur, nimic nu ne opreste sa repetam k-fold cross validation pentru diferite permutari initiale ale setului de antrenare si sa calculam la final media rezultatelor (media mediilor). Estimarea este mai robusta, dar mare consumatoare de timp. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selectarea modelului"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valorea hiperparametrului $k$ a fost aleasa mai sus in mod arbitrar. Se pune problema: care este cea mai buna valoare a lui $k$? Putem face acest lucru printr-o cautare sistematica a lui $k$, de exemplu $k \\in \\{ 1, 2, \\dots, 20 \\}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_score_for_model(k):\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(model, X, y, cv=10, scoring='accuracy')\n",
    "    return scores.mean()\n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
